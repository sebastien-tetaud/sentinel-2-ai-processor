{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5345d534",
   "metadata": {},
   "source": [
    "# Create Sentinel2Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b51a177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import natsort\n",
    "import glob\n",
    "from PIL import Image\n",
    "import natsort\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd51429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_VERSION = \"V2\"\n",
    "TRAIN_DIR = f\"/mnt/disk/dataset/sentinel-ai-processor/{DATASET_VERSION}/train/\"\n",
    "VAL_DIR = f\"/mnt/disk/dataset/sentinel-ai-processor/{DATASET_VERSION}/val/\"\n",
    "TEST_DIR = f\"/mnt/disk/dataset/sentinel-ai-processor/{DATASET_VERSION}/test/\"\n",
    "\n",
    "\n",
    "\n",
    "def prepare_paths(path_dir):\n",
    "    \n",
    "    \n",
    "    df_input = pd.read_csv(f\"{path_dir}/input.csv\")\n",
    "    df_output = pd.read_csv(f\"{path_dir}/target.csv\")\n",
    "\n",
    "    df_input[\"path\"] = df_input[\"Name\"].apply(lambda x: os.path.join(path_dir, \"input\", os.path.basename(x).replace(\".SAFE\",\"\")))\n",
    "    df_output[\"path\"] = df_output[\"Name\"].apply(lambda x: os.path.join(path_dir, \"input\", os.path.basename(x).replace(\".SAFE\",\"\")))\n",
    "    \n",
    "    return df_input, df_output\n",
    "\n",
    "\n",
    "df_input, df_output =  prepare_paths(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ba03f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(band, lower_percent=2, upper_percent=98):\n",
    "    \"\"\"\n",
    "    Apply percentile stretching to enhance contrast, only considering valid pixels.\n",
    "    \n",
    "    Args:\n",
    "        band: Input image band as numpy array\n",
    "        lower_percent: Lower percentile boundary (default 2%)\n",
    "        upper_percent: Upper percentile boundary (default 98%)\n",
    "        \n",
    "    Returns:\n",
    "        Normalized band with values in [0, 1]\n",
    "    \"\"\"\n",
    "    # Create mask for valid pixels\n",
    "    valid_mask = (band > 0)\n",
    "    \n",
    "    # If no valid pixels, return zeros\n",
    "    if not np.any(valid_mask):\n",
    "        return np.zeros_like(band, dtype=np.float32)\n",
    "    \n",
    "    # Extract valid pixels for percentile calculation\n",
    "    valid_pixels = band[valid_mask]\n",
    "    # Calculate percentiles based only on valid pixels\n",
    "    lower = np.percentile(valid_pixels, lower_percent)\n",
    "    upper = np.percentile(valid_pixels, upper_percent)\n",
    "    \n",
    "    # Create a copy to avoid modifying the original\n",
    "    result = band.copy().astype(np.float32)\n",
    "    \n",
    "    # Apply stretching only to valid pixels\n",
    "    result[valid_mask] = np.clip((band[valid_mask] - lower) / (upper - lower), 0, 1)\n",
    "    \n",
    "    # Set invalid pixels to 0\n",
    "    result[~valid_mask] = 0\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def read_images(product_paths):\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for path in product_paths:\n",
    "\n",
    "        data = Image.open(path)\n",
    "        data = np.array(data)\n",
    "        data = normalize(data)\n",
    "        \n",
    "        images.append(data)\n",
    "        \n",
    "    \n",
    "    \n",
    "    images = np.dstack(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3884f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentinel2Dataset(Dataset):\n",
    "    def __init__(self, df_x, df_y,\n",
    "                 train,\n",
    "                 augmentation,\n",
    "                 img_size):\n",
    "\n",
    "        self.df_x = df_x\n",
    "        self.df_y = df_y\n",
    "        self.train = train\n",
    "        self.augmentation = augmentation\n",
    "        self.img_size = img_size\n",
    "        # self.transform = get_transforms(train=self.train,\n",
    "        #                                 augmentation=self.augmentation)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load images\n",
    "        x_paths = natsort.natsorted(glob.glob(os.path.join(self.df_x[\"path\"][index], \"*.png\"), recursive=False))\n",
    "        x_data = read_images(x_paths)\n",
    "        x_data = cv2.resize(x_data, (self.img_size, self.img_size), interpolation=cv2.INTER_AREA)\n",
    "        x_data = torch.from_numpy(x_data).float()\n",
    "        x_data = torch.permute(x_data, (2, 0, 1))  # HWC to CHW\n",
    "\n",
    "        y_paths = natsort.natsorted(glob.glob(os.path.join(self.df_x[\"path\"][index], \"*.png\"), recursive=False))\n",
    "        y_data = read_images(y_paths)\n",
    "        y_data = cv2.resize(y_data, (self.img_size, self.img_size), interpolation=cv2.INTER_AREA)\n",
    "        y_data = torch.from_numpy(y_data).float()\n",
    "        y_data = torch.permute(y_data, (2, 0, 1))  # HWC to CHW\n",
    "\n",
    "        # transformed = self.transform(image=x_data, mask=y_data)\n",
    "        # y_data = transformed[\"mask\"]\n",
    "        # x_data = transformed[\"image\"]\n",
    "\n",
    "        return x_data, y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff9f381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = Sentinel2Dataset(df_x=df_input, df_y=df_output, train=True, augmentation=False, img_size=1024)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a79e61af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 1024, 1024]) torch.Size([16, 3, 1024, 1024])\n",
      "torch.Size([16, 3, 1024, 1024]) torch.Size([16, 3, 1024, 1024])\n",
      "torch.Size([16, 3, 1024, 1024]) torch.Size([16, 3, 1024, 1024])\n",
      "torch.Size([16, 3, 1024, 1024]) torch.Size([16, 3, 1024, 1024])\n",
      "torch.Size([16, 3, 1024, 1024]) torch.Size([16, 3, 1024, 1024])\n",
      "torch.Size([16, 3, 1024, 1024]) torch.Size([16, 3, 1024, 1024])\n",
      "torch.Size([16, 3, 1024, 1024]) torch.Size([16, 3, 1024, 1024])\n",
      "torch.Size([16, 3, 1024, 1024]) torch.Size([16, 3, 1024, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/queues.py\", line 259, in _feed\n",
      "    reader_close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 178, in close\n",
      "    self._close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "<function _ConnectionBase.__del__ at 0x7071e4343380>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 133, in __del__\n",
      "    self._close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/queues.py\", line 259, in _feed\n",
      "    reader_close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 178, in close\n",
      "    self._close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/queues.py\", line 259, in _feed\n",
      "    reader_close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 178, in close\n",
      "    self._close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Exception ignored in: <function _ConnectionBase.__del__ at 0x7071e4343380>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 133, in __del__\n",
      "    self._close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/queues.py\", line 259, in _feed\n",
      "    reader_close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 178, in close\n",
      "    self._close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/queues.py\", line 259, in _feed\n",
      "    reader_close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 178, in close\n",
      "    self._close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/queues.py\", line 259, in _feed\n",
      "    reader_close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 178, in close\n",
      "    self._close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/queues.py\", line 259, in _feed\n",
      "    reader_close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 178, in close\n",
      "    self._close()\n",
      "  File \"/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai_processor/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai_processor/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1458\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data)\n\u001b[32m   1457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1458\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1461\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai_processor/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1420\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1416\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1418\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1420\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1421\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1422\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai_processor/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1251\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1239\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1240\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1248\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1254\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1256\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    112\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py:440\u001b[39m, in \u001b[36mConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     r = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai_processor/lib/python3.12/multiprocessing/connection.py:1135\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1132\u001b[39m     deadline = time.monotonic() + timeout\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[32m   1137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [key.fileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai_processor/lib/python3.12/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for x_data, y_data in train_loader:\n",
    "    \n",
    "    print(x_data.shape, x_data.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f123f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_processor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
