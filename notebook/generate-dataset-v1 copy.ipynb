{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ccb655",
   "metadata": {},
   "source": [
    "## Get Sentinel 2 Data on CDSE using ODATA and Boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b2e9537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pystac_client\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from loguru import logger\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97a8dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cdse_query_url(\n",
    "    collection_name=\"SENTINEL-2\",\n",
    "    product_type=\"MSIL2A\",\n",
    "    polygon=None,\n",
    "    start_interval=None,\n",
    "    end_interval=None,\n",
    "    max_cloud_cover=100,\n",
    "    max_items=1000,\n",
    "    additional_filters=None,\n",
    "    orderby=\"ContentDate/Start\"  # Add orderby parameter with default value\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a query URL for the Copernicus Data Space Ecosystem OData API.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    collection_name : str\n",
    "        The collection name (e.g., 'SENTINEL-2', 'SENTINEL-1')\n",
    "    product_type : str\n",
    "        The product type (e.g., 'MSIL2A', 'MSIL1C', 'GRD')\n",
    "    polygon : str\n",
    "        WKT polygon string for spatial filtering\n",
    "    start_interval : str\n",
    "        Start time in ISO format with Z for UTC (e.g., '2023-01-01T00:00:00.000Z')\n",
    "    end_interval : str\n",
    "        End time in ISO format with Z for UTC (e.g., '2023-01-31T23:59:59.999Z')\n",
    "    max_cloud_cover : int\n",
    "        Maximum cloud cover percentage (0-100)\n",
    "    max_items : int\n",
    "        Maximum number of items to return\n",
    "    additional_filters : list\n",
    "        List of additional filter strings to add to the query\n",
    "    orderby : str or None\n",
    "        Field to order results by (e.g., 'ContentDate/Start', 'ContentDate/Start desc')\n",
    "        Set to None to skip ordering\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Complete URL for the OData API query\n",
    "    \"\"\"\n",
    "\n",
    "    # Basic filter for collection\n",
    "    filter_parts = [f\"Collection/Name eq '{collection_name}'\"]\n",
    "\n",
    "    # Add spatial filter if provided\n",
    "    if polygon:\n",
    "        filter_parts.append(f\"OData.CSC.Intersects(area=geography'SRID=4326;{polygon}')\")\n",
    "\n",
    "    # Add product type filter\n",
    "    if product_type:\n",
    "        filter_parts.append(f\"contains(Name,'{product_type}')\")\n",
    "\n",
    "    # Add temporal filters if provided\n",
    "    if start_interval:\n",
    "        filter_parts.append(f\"ContentDate/Start gt {start_interval}\")\n",
    "    if end_interval:\n",
    "        filter_parts.append(f\"ContentDate/Start lt {end_interval}\")\n",
    "\n",
    "    # Add cloud cover filter if applicable\n",
    "    # Only add for optical sensors (Sentinel-2)\n",
    "    if collection_name == 'SENTINEL-2' and max_cloud_cover < 100:\n",
    "        filter_parts.append(\n",
    "            f\"Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and \"\n",
    "            f\"att/OData.CSC.DoubleAttribute/Value le {max_cloud_cover})\"\n",
    "        )\n",
    "\n",
    "    # Add any additional filters\n",
    "    if additional_filters:\n",
    "        filter_parts.extend(additional_filters)\n",
    "\n",
    "    # Construct the URL with all filters\n",
    "    filter_string = \" and \".join(filter_parts)\n",
    "    url = f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter={filter_string}\"\n",
    "\n",
    "    # Add orderby parameter if specified\n",
    "    if orderby:\n",
    "        url += f\"&$orderby={orderby}\"\n",
    "\n",
    "    # Add top parameter for limiting results\n",
    "    url += f\"&$top={max_items}\"\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13d3e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "notebook_dir = os.path.abspath('')\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Now import the module\n",
    "from src.auth.auth import S3Connector\n",
    "from src.utils.utils import extract_s3_path_from_url\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "ACCESS_KEY_ID = os.environ.get(\"ACCESS_KEY_ID\")\n",
    "SECRET_ACCESS_KEY = os.environ.get(\"SECRET_ACCESS_KEY\")\n",
    "ENDPOINT_URL = 'https://eodata.dataspace.copernicus.eu'\n",
    "ENDPOINT_STAC = \"https://stac.dataspace.copernicus.eu/v1/\"\n",
    "DATASET_VERSION = \"V1\"\n",
    "BUKETNAME = \"eodata\"\n",
    "BASE_DIR = f\"/mnt/disk/dataset/sentinel-ai-processor\"\n",
    "DATASET_DIR = f\"{BASE_DIR}/{DATASET_VERSION}\"\n",
    "BANDS = ['B02', 'B03', 'B04']\n",
    "\n",
    "connector = S3Connector(\n",
    "    endpoint_url=ENDPOINT_URL,\n",
    "    access_key_id=ACCESS_KEY_ID,\n",
    "    secret_access_key=SECRET_ACCESS_KEY,\n",
    "    region_name='default'\n",
    ")\n",
    "# Get S3 client and resource from the connector instance\n",
    "s3 = connector.get_s3_resource()\n",
    "s3_client = connector.get_s3_client()\n",
    "buckets = connector.list_buckets()\n",
    "bucket = s3.Bucket(BUKETNAME)\n",
    "\n",
    "input_dir = os.path.join(DATASET_DIR, \"input\")\n",
    "output_dir = os.path.join(DATASET_DIR, \"output\")\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bba8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bounding box and date range\n",
    "# Australia\n",
    "# bbox = [146.5, -22.0, 149.5, -20.0]\n",
    "# Central Europe bbox\n",
    "bbox = [3.2833, 45.3833, 11.2, 50.1833]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b583dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_77194c80cafa5e26e55efc82f5370b07 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_77194c80cafa5e26e55efc82f5370b07&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_77194c80cafa5e26e55efc82f5370b07 = L.map(\n",
       "                &quot;map_77194c80cafa5e26e55efc82f5370b07&quot;,\n",
       "                {\n",
       "                    center: [47.7833, 7.24165],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    ...{\n",
       "  &quot;zoom&quot;: 7,\n",
       "  &quot;zoomControl&quot;: true,\n",
       "  &quot;preferCanvas&quot;: false,\n",
       "}\n",
       "\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_b8c081d577b7de8be6d53be76e128482 = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {\n",
       "  &quot;minZoom&quot;: 0,\n",
       "  &quot;maxZoom&quot;: 19,\n",
       "  &quot;maxNativeZoom&quot;: 19,\n",
       "  &quot;noWrap&quot;: false,\n",
       "  &quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;,\n",
       "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
       "  &quot;detectRetina&quot;: false,\n",
       "  &quot;tms&quot;: false,\n",
       "  &quot;opacity&quot;: 1,\n",
       "}\n",
       "\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_b8c081d577b7de8be6d53be76e128482.addTo(map_77194c80cafa5e26e55efc82f5370b07);\n",
       "        \n",
       "    \n",
       "            map_77194c80cafa5e26e55efc82f5370b07.fitBounds(\n",
       "                [[45.3833, 3.2833], [50.1833, 11.2]],\n",
       "                {}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            var rectangle_181d46a6b38bff6399cf96998bd0e0b4 = L.rectangle(\n",
       "                [[45.3833, 3.2833], [50.1833, 11.2]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;red&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;red&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1.0, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_77194c80cafa5e26e55efc82f5370b07);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7747e374b3e0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "\n",
    "\n",
    "# Calculate the center of the bbox\n",
    "center_longitude = (bbox[0] + bbox[2]) / 2\n",
    "center_latitude = (bbox[1] + bbox[3]) / 2\n",
    "\n",
    "# Create a Folium map centered on the bbox center\n",
    "m = folium.Map(location=[center_latitude, center_longitude], zoom_start=7)\n",
    "\n",
    "# Fit the map to the bbox\n",
    "m.fit_bounds([[bbox[1], bbox[0]], [bbox[3], bbox[2]]])\n",
    "\n",
    "# Draw the bbox as a rectangle on the map\n",
    "folium.Rectangle([(bbox[1], bbox[0]), (bbox[3], bbox[2])], \n",
    "                 color='red', \n",
    "                 fill=True, \n",
    "                 fill_color='red', \n",
    "                 fill_opacity=0.2).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eee849f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query parameters:\n",
      "Bounding box: [3.2833, 45.3833, 11.2, 50.1833]\n",
      "Date range: 2025-01-01 to 2025-01-15\n",
      "Max items per request: 1000\n",
      "Max cloud cover: 100%\n",
      "L1C Items for 2025-01-01/2025-01-11: 217\n",
      "L2A Items for 2025-01-01/2025-01-11: 217\n",
      "####\n",
      "L1C Items for 2025-01-11/2025-01-15: 94\n",
      "L2A Items for 2025-01-11/2025-01-15: 94\n",
      "####\n"
     ]
    }
   ],
   "source": [
    "# Set up loguru logger\n",
    "log_filename = f\"{DATASET_DIR}/sentinel_query_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "# Remove the default sink and add custom ones\n",
    "logger.remove()\n",
    "# Add a sink for the file with the format you want\n",
    "logger.add(log_filename, format=\"{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}\")\n",
    "# Add a sink for stdout with a simpler format\n",
    "logger.add(lambda msg: print(msg, end=\"\"), colorize=True, format=\"{message}\")\n",
    "\n",
    "start_date = datetime(2025, 1, 1)\n",
    "end_date = datetime(2025, 1, 15)\n",
    "max_items = 1000\n",
    "max_cloud_cover = 100\n",
    "\n",
    "# Log query parameters\n",
    "logger.info(f\"Query parameters:\")\n",
    "logger.info(f\"Bounding box: {bbox}\")\n",
    "logger.info(f\"Date range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "logger.info(f\"Max items per request: {max_items}\")\n",
    "logger.info(f\"Max cloud cover: {max_cloud_cover}%\")\n",
    "# Generate the polygon string from bbox [minx, miny, maxx, maxy]\n",
    "polygon = f\"POLYGON (({bbox[0]} {bbox[1]}, {bbox[0]} {bbox[3]}, {bbox[2]} {bbox[3]}, {bbox[2]} {bbox[1]}, {bbox[0]} {bbox[1]}))\"\n",
    "\n",
    "# Initialize empty lists to store all results\n",
    "all_l1c_results = []\n",
    "all_l2a_results = []\n",
    "\n",
    "# Loop through the date range with a step of 5 days\n",
    "current_date = start_date\n",
    "while current_date < end_date:\n",
    "    # Calculate the end of the current 5-day interval\n",
    "    next_date = min(current_date + timedelta(days=10), end_date)\n",
    "\n",
    "    # Format the dates as required for the OData query (ISO format with Z for UTC)\n",
    "    start_interval = f\"{current_date.strftime('%Y-%m-%dT00:00:00.000Z')}\"\n",
    "    end_interval = f\"{next_date.strftime('%Y-%m-%dT23:59:59.999Z')}\"\n",
    "\n",
    "    date_interval = f\"{current_date.strftime('%Y-%m-%d')}/{next_date.strftime('%Y-%m-%d')}\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        l2a_query_url = create_cdse_query_url(\n",
    "            product_type=\"MSIL2A\",\n",
    "            polygon=polygon,\n",
    "            start_interval=start_interval,\n",
    "            end_interval=end_interval,\n",
    "            max_cloud_cover=max_cloud_cover,\n",
    "            max_items=max_items,\n",
    "            orderby=\"ContentDate/Start\"\n",
    "        )\n",
    "        # Search for Sentinel-2 L2A products for this interval\n",
    "        l2a_json = requests.get(l2a_query_url).json()\n",
    "\n",
    "        # Add interval as metadata to each item\n",
    "        l2a_results = l2a_json.get('value', [])\n",
    "        for item in l2a_results:\n",
    "            item['query_interval'] = date_interval\n",
    "\n",
    "\n",
    "        l1c_query_url = create_cdse_query_url(\n",
    "            product_type=\"MSIL1C\",\n",
    "            polygon=polygon,\n",
    "            start_interval=start_interval,\n",
    "            end_interval=end_interval,\n",
    "            max_cloud_cover=max_cloud_cover,\n",
    "            max_items=max_items,\n",
    "            orderby=\"ContentDate/Start\"\n",
    "        )\n",
    "        # Search for Sentinel-2 L1C products for this interval\n",
    "        l1c_json = requests.get(l1c_query_url).json()\n",
    "\n",
    "        # Add interval as metadata to each item\n",
    "        l1c_results = l1c_json.get('value', [])\n",
    "        for item in l1c_results:\n",
    "            item['query_interval'] = date_interval\n",
    "\n",
    "        # Count L1C products\n",
    "        l1c_count = len(l1c_results)\n",
    "        l2a_count = len(l2a_results)\n",
    "\n",
    "        if l1c_count == l2a_count:\n",
    "            # Append to the overall results list?\n",
    "            all_l1c_results.extend(l1c_results)\n",
    "            all_l2a_results.extend(l2a_results)\n",
    "        else:\n",
    "            logger.warning(f\"Mismatch in counts for {date_interval}: L1C={l1c_count}, L2A={l2a_count}\")\n",
    "            all_l1c_results.extend(l1c_results)\n",
    "            all_l2a_results.extend(l2a_results)\n",
    "\n",
    "        # Print results for this interval\n",
    "        logger.info(f\"L1C Items for {date_interval}: {l1c_count}\")\n",
    "        logger.info(f\"L2A Items for {date_interval}: {l2a_count}\")\n",
    "        logger.info(\"####\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing interval {date_interval}: {str(e)}\")\n",
    "\n",
    "    # Move to the next n-day interval\n",
    "    current_date = next_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2201701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create DataFrames from the collected results\n",
    "df_l1c = pd.DataFrame(all_l1c_results)\n",
    "df_l2a = pd.DataFrame(all_l2a_results)\n",
    "\n",
    "# Select only the required columns\n",
    "df_l2a = df_l2a[[\"Name\", \"S3Path\", \"Footprint\", \"GeoFootprint\"]]\n",
    "df_l1c = df_l1c[[\"Name\", \"S3Path\", \"Footprint\", \"GeoFootprint\"]]\n",
    "\n",
    "df_l1c.to_csv(f\"{DATASET_DIR}/input_l1c.csv\")\n",
    "df_l2a.to_csv(f\"{DATASET_DIR}/output_l2a.csv\")\n",
    "\n",
    "# Define the function to manipulate the Sentinel ID\n",
    "def remove_last_segment_rsplit(sentinel_id):\n",
    "    # Split from the right side, max 1 split\n",
    "    parts = sentinel_id.rsplit('_', 1)\n",
    "    return parts[0]\n",
    "\n",
    "# Create the id_key column based on the function\n",
    "df_l2a['id_key'] = df_l2a['Name'].apply(remove_last_segment_rsplit)\n",
    "df_l2a['id_key'] = df_l2a['id_key'].str.replace('MSIL2A_', 'MSIL1C_')  # Replace prefix for matching\n",
    "df_l1c['id_key'] = df_l1c['Name'].apply(remove_last_segment_rsplit)\n",
    "\n",
    "# Step 1: Drop duplicates in each DataFrame and keep the first occurrence\n",
    "df_l2a = df_l2a.drop_duplicates(subset='id_key', keep='first')\n",
    "df_l1c = df_l1c.drop_duplicates(subset='id_key', keep='first')\n",
    "\n",
    "# Step 2: Find the common id_keys to ensure both DataFrames have the same order\n",
    "df_l2a = df_l2a[df_l2a['id_key'].isin(df_l1c['id_key'])]\n",
    "df_l1c = df_l1c[df_l1c['id_key'].isin(df_l2a['id_key'])]\n",
    "\n",
    "# Step 3: Align the DataFrames by the order of id_key\n",
    "df_l2a = df_l2a.set_index('id_key')\n",
    "df_l1c = df_l1c.set_index('id_key')\n",
    "\n",
    "df_l2a = df_l2a.loc[df_l1c.index].reset_index()\n",
    "df_l1c = df_l1c.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49897d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l1c = df_l1c.sample(n=1500, random_state=42)\n",
    "df_l2a = df_l2a.sample(n=1500, random_state=42)\n",
    "df_l1c = df_l1c.reset_index(drop=True)\n",
    "df_l2a = df_l2a.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028a532",
   "metadata": {},
   "source": [
    "## Generate random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65d2bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(min(len(df_l1c), len(df_l2a))):\n",
    "    if df_l1c['id_key'][i] == df_l2a['id_key'][i]:\n",
    "        print(f\"Match: {df_l1c['id_key'][i]} == {df_l2a['id_key'][i]}\")\n",
    "    else:\n",
    "        print(f\"Mismatch: {df_l1c['id_key'][i]} != {df_l2a['id_key'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4fa82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l1c.to_csv(f\"{DATASET_DIR}/sample_input_l1c.csv\")\n",
    "df_l2a.to_csv(f\"{DATASET_DIR}/sample_output_l2a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "def parse_safe_manifest(content: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Parse a Sentinel SAFE manifest file and extract href attributes.\n",
    "\n",
    "    Args:\n",
    "        manifest_path (str): Path to the manifest.safe file\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing href values and file information,\n",
    "                     or None if an error occurred\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        # Parse the content\n",
    "        root = ET.fromstring(content)\n",
    "\n",
    "        # Extract all elements with an href attribute using a generic approach\n",
    "        hrefs = []\n",
    "        for elem in root.findall(\".//*[@href]\"):\n",
    "            href = elem.get('href')\n",
    "            if href:\n",
    "                hrefs.append(href)\n",
    "\n",
    "        # Create DataFrame with href values and file information\n",
    "        df_files = pd.DataFrame({\n",
    "            'href': hrefs,\n",
    "            'file_type': [href.split('.')[-1] if '.' in href else 'unknown' for href in hrefs],\n",
    "            'file_name': [os.path.basename(href) for href in hrefs]\n",
    "        })\n",
    "\n",
    "\n",
    "        return df_files\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        logger.error(f\"XML parsing error : {str(e)}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing manifest: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def download_manifest(s3_client, bucket_name, s3_path, max_attempts=5, retry_delay=2):\n",
    "    \"\"\"\n",
    "    Download and parse a Sentinel-2 product manifest file from S3.\n",
    "    \n",
    "    Args:\n",
    "        s3_client: Boto3 S3 client\n",
    "        bucket_name (str): S3 bucket name\n",
    "        s3_path (str): Base S3 path to the product\n",
    "        max_attempts (int): Maximum number of download attempts\n",
    "        retry_delay (int): Seconds to wait between retry attempts\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (success (bool), dataframe of files or None)\n",
    "    \"\"\"\n",
    "    # Extract base S3 URL and create manifest URL\n",
    "    s3_base_url = extract_s3_path_from_url(s3_path).replace(\"/eodata\", \"\")\n",
    "    s3_manifest_url = f\"{s3_base_url}/manifest.safe\"\n",
    "    \n",
    "    # Try to download manifest file with retry logic\n",
    "    attempt = 0\n",
    "    content = None\n",
    "    \n",
    "    while attempt < max_attempts:\n",
    "        try:\n",
    "            # Get the manifest file\n",
    "            response = s3_client.get_object(Bucket=bucket_name, Key=s3_manifest_url)\n",
    "            \n",
    "            # Check if successful\n",
    "            if response[\"ResponseMetadata\"]['HTTPStatusCode'] == 200:\n",
    "                content = response['Body'].read()\n",
    "                logger.info(f\"Downloaded manifest from {s3_manifest_url}\")\n",
    "                break\n",
    "            else:\n",
    "                logger.warning(f\"Unexpected status: {response['ResponseMetadata']['HTTPStatusCode']}\")\n",
    "                attempt += 1\n",
    "                time.sleep(retry_delay)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error downloading manifest: {str(e)}\")\n",
    "            attempt += 1\n",
    "            time.sleep(retry_delay)\n",
    "    \n",
    "    if content is None:\n",
    "        logger.error(f\"Failed to download manifest after {max_attempts} attempts\")\n",
    "        return False, None\n",
    "   \n",
    "    # Parse the manifest into a dataframe\n",
    "    df_files = parse_safe_manifest(content=content)\n",
    "    \n",
    "    return df_files\n",
    "\n",
    "\n",
    "def filter_band_files(df_files, bands=None, product_type=None, resolution=None):\n",
    "    \"\"\"\n",
    "    Filter a dataframe for Sentinel-2 band files supporting both L1C and L2A formats.\n",
    "\n",
    "    Args:\n",
    "        df_files (pd.DataFrame): DataFrame with 'href' column containing file paths\n",
    "        bands (list, optional): List of band names to filter for (e.g., ['B02', 'B03', 'B04']).\n",
    "                               If None, defaults to RGB bands.\n",
    "        product_type (str, optional): Product type ('L1C' or 'L2A'). If None, both types are included.\n",
    "        resolution (str or int, optional): Specific resolution to filter for L2A products ('10m', '20m', '60m' or 10, 20, 60).\n",
    "                                         If None, includes all resolutions.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame containing only requested band files\n",
    "    \"\"\"\n",
    "    # Define default bands to filter if not specified\n",
    "    if bands is None:\n",
    "        bands = ['B02', 'B03', 'B04']  # RGB bands by default\n",
    "\n",
    "    # Convert resolution to string if it's an integer\n",
    "    if resolution is not None:\n",
    "        resolution = str(resolution)\n",
    "\n",
    "    # Build regex patterns to match both L1C and L2A formats\n",
    "    band_patterns = []\n",
    "\n",
    "    for band in bands:\n",
    "        # L1C format: IMG_DATA/*_B02.jp2\n",
    "        if product_type is None or product_type.upper() == 'L1C':\n",
    "            band_patterns.append(r'IMG_DATA/.*_' + band + r'\\.jp2')\n",
    "\n",
    "        # L2A formats with correct pattern: IMG_DATA/R20m/T55KGR_20200103T001101_B02_20m.jp2\n",
    "        if product_type is None or product_type.upper() == 'L2A':\n",
    "            if resolution:\n",
    "                # If specific resolution is provided, filter for that resolution\n",
    "                band_patterns.append(r'IMG_DATA/R' + resolution + r'm/.*_' + band + r'_' + resolution + r'm\\.jp2')\n",
    "            else:\n",
    "                # If no resolution is specified, include all resolutions\n",
    "                band_patterns.extend([\n",
    "                    r'IMG_DATA/R10m/.*_' + band + r'_10m\\.jp2',\n",
    "                    r'IMG_DATA/R20m/.*_' + band + r'_20m\\.jp2',\n",
    "                    r'IMG_DATA/R60m/.*_' + band + r'_60m\\.jp2'\n",
    "                ])\n",
    "\n",
    "    filter_condition = False\n",
    "    for pattern in band_patterns:\n",
    "        filter_condition = filter_condition | df_files['href'].str.contains(pattern, regex=True)\n",
    "\n",
    "    df_gr = df_files[filter_condition].copy()  # Create a copy to avoid the warning\n",
    "\n",
    "\n",
    "    # Remove leading ./ from href paths\n",
    "    df_gr['href'] = df_gr['href'].str.replace(r'^\\./', '', regex=True)\n",
    "\n",
    "    return df_gr\n",
    "\n",
    "\n",
    "def download_bands(s3_client, bucket, bucket_name, df, bands, product_type, resolution, output_dir, max_attempts=10, retry_delay=10):\n",
    "    \"\"\"\n",
    "    Download Sentinel-2 band files from S3 based on dataframe information.\n",
    "    \n",
    "    Args:\n",
    "        s3_client: S3 client object\n",
    "        bucket: S3 bucket object\n",
    "        bucket_name: Name of the S3 bucket\n",
    "        df (pd.DataFrame): DataFrame with 'S3Path' column containing S3 paths\n",
    "        bands (list): List of bands to download\n",
    "        product_type (str): Product type ('L1C' or 'L2A')\n",
    "        resolution (int, optional): Resolution in meters. Required for L2A products.\n",
    "        output_dir (str): Base directory to save files\n",
    "        max_attempts (int): Maximum number of download attempts\n",
    "        retry_delay (int): Delay between retry attempts in seconds\n",
    "    \"\"\"\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract base S3 URL\n",
    "        s3_base_url = extract_s3_path_from_url(row['S3Path']).replace(\"/eodata\",\"\")\n",
    "        s3_manifest_url = f\"{s3_base_url}/manifest.safe\"\n",
    "        _, filename = os.path.split(s3_manifest_url)\n",
    "        \n",
    "        # Try to download manifest file with retry logic\n",
    "        attempt = 0\n",
    "        content = None\n",
    "        \n",
    "        while attempt < max_attempts:\n",
    "            try:\n",
    "                # Get the manifest file\n",
    "                response = s3_client.get_object(Bucket=bucket_name, Key=s3_manifest_url)\n",
    "                # Check if successful\n",
    "                if response[\"ResponseMetadata\"]['HTTPStatusCode'] == 200:\n",
    "                    content = response['Body'].read()\n",
    "                    logger.info(f\"Downloaded manifest from {s3_manifest_url}\")\n",
    "                    break\n",
    "                else:\n",
    "                    logger.warning(f\"Unexpected status: {response['ResponseMetadata']['HTTPStatusCode']}\")\n",
    "                    attempt += 1\n",
    "                    time.sleep(retry_delay)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error downloading manifest: {str(e)}\")\n",
    "                attempt += 1\n",
    "                time.sleep(retry_delay)\n",
    "        \n",
    "        if content is None:\n",
    "            logger.error(f\"Failed to download manifest after {max_attempts} attempts, skipping this product\")\n",
    "            continue\n",
    "            \n",
    "        df_tmp = parse_safe_manifest(content=content)\n",
    "        df_bands = filter_band_files(df_tmp, bands=bands, product_type=product_type, resolution=resolution)\n",
    "\n",
    "        for gr in df_bands['href']:\n",
    "            # Create full S3 URL for the band file\n",
    "            band_s3_url = f\"{s3_base_url}/{gr}\"\n",
    "            \n",
    "            # Extract just the filename from the path\n",
    "            filename = os.path.basename(gr)\n",
    "            \n",
    "            # Extract product ID for folder structure\n",
    "            path_safe = s3_base_url.split(os.sep)[7].replace(\".SAFE\",\"\")\n",
    "            path_save = os.path.join(output_dir, path_safe)\n",
    "            os.makedirs(path_save, exist_ok=True)\n",
    "\n",
    "            # Download the file with retry logic\n",
    "            attempt = 0\n",
    "            \n",
    "            while attempt < max_attempts:\n",
    "                try:\n",
    "                    # Download the band file\n",
    "                    bucket.download_file(band_s3_url, f\"{path_save}/{filename}\")\n",
    "                    logger.info(f\"Downloaded {filename} to {path_save}\")\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Error downloading band file {filename}: {str(e)}\")\n",
    "                    attempt += 1\n",
    "                    if attempt < max_attempts:\n",
    "                        logger.info(f\"Retrying download of {filename}, attempt {attempt+1} of {max_attempts}\")\n",
    "                        time.sleep(retry_delay)\n",
    "                    else:\n",
    "                        logger.error(f\"Failed to download {filename} after {max_attempts} attempts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c308ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_filename = f\"{DATASET_DIR}/sentinel_download_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "# Remove the default sink and add custom ones\n",
    "logger.remove()\n",
    "# Add a sink for the file with the format you want\n",
    "logger.add(log_filename, format=\"{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}\")\n",
    "# Add a sink for stdout with a simpler format\n",
    "logger.add(lambda msg: print(msg, end=\"\"), colorize=True, format=\"{message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ad21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_bands(s3_client=s3_client, bucket=bucket, bucket_name=BUKETNAME, df=df_l1c,\n",
    "                product_type=\"L1C\", bands=BANDS, resolution=None, output_dir=input_dir,\n",
    "                max_attempts=10, retry_delay=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5818b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_bands(s3_client=s3_client, bucket=bucket, bucket_name=BUKETNAME, df=df_l2a,\n",
    "                product_type=\"L2A\", bands=BANDS, resolution=10, output_dir=output_dir,\n",
    "                max_attempts=10, retry_delay=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8cbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Define your bounding box\n",
    "bbox = [3.2833, 45.3833, 11.2, 50.1833]\n",
    "# Convert bbox to WKT polygon\n",
    "polygon = f\"POLYGON(({bbox[0]} {bbox[1]}, {bbox[2]} {bbox[1]}, {bbox[2]} {bbox[3]}, {bbox[0]} {bbox[3]}, {bbox[0]} {bbox[1]}))\"\n",
    "\n",
    "# Format dates\n",
    "start_date = \"2025-01-01T00:00:00.000Z\"\n",
    "end_date = \"2025-01-15T23:59:59.999Z\"\n",
    "\n",
    "# Use custom additional filter to include both L1C and L2A products\n",
    "additional_filters = [\"(contains(Name,'MSIL1C') or contains(Name,'MSIL2A'))\"]\n",
    "\n",
    "# Remove the default product_type filter by setting it to None\n",
    "url = create_cdse_query_url(\n",
    "    collection_name=\"SENTINEL-2\",\n",
    "    product_type=None,  # Set to None because we're using additional_filters\n",
    "    polygon=polygon,\n",
    "    start_interval=start_date,\n",
    "    end_interval=end_date,\n",
    "    max_cloud_cover=100,\n",
    "    max_items=1000,\n",
    "    additional_filters=additional_filters\n",
    ")\n",
    "# Add count parameter manually\n",
    "url += \"&$count=true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "695e8b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2a_json = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa0d7692",
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = l2a_json.get('value', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69b5b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20b654b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@odata.mediaContentType</th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>ContentType</th>\n",
       "      <th>ContentLength</th>\n",
       "      <th>OriginDate</th>\n",
       "      <th>PublicationDate</th>\n",
       "      <th>ModificationDate</th>\n",
       "      <th>Online</th>\n",
       "      <th>EvictionDate</th>\n",
       "      <th>S3Path</th>\n",
       "      <th>Checksum</th>\n",
       "      <th>ContentDate</th>\n",
       "      <th>Footprint</th>\n",
       "      <th>GeoFootprint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>02382b16-7ac4-44c7-b095-1fcd2c7e0770</td>\n",
       "      <td>S2A_MSIL2A_20250101T104441_N0511_R008_T31TGM_2...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>961041063</td>\n",
       "      <td>2025-01-01T17:37:03.000000Z</td>\n",
       "      <td>2025-01-01T17:47:35.830573Z</td>\n",
       "      <td>2025-01-01T17:58:34.626246Z</td>\n",
       "      <td>True</td>\n",
       "      <td>9999-12-31T23:59:59.999999Z</td>\n",
       "      <td>/eodata/Sentinel-2/MSI/L2A/2025/01/01/S2A_MSIL...</td>\n",
       "      <td>[{'Value': '4230923f6a24befaccaddde4dddf73c2',...</td>\n",
       "      <td>{'Start': '2025-01-01T10:44:41.024000Z', 'End'...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((6.73372898013687...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[6.733728...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>046245ff-ff34-4cec-879a-d768ad514dbc</td>\n",
       "      <td>S2A_MSIL2A_20250101T104441_N0511_R008_T31UEQ_2...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>563963564</td>\n",
       "      <td>2025-01-01T17:36:16.000000Z</td>\n",
       "      <td>2025-01-01T17:48:15.562066Z</td>\n",
       "      <td>2025-01-01T17:48:43.236298Z</td>\n",
       "      <td>True</td>\n",
       "      <td>9999-12-31T23:59:59.999999Z</td>\n",
       "      <td>/eodata/Sentinel-2/MSI/L2A/2025/01/01/S2A_MSIL...</td>\n",
       "      <td>[{'Value': 'f8e719d4ff70edd1384f7619458a4ea5',...</td>\n",
       "      <td>{'Start': '2025-01-01T10:44:41.024000Z', 'End'...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((3.37371033145457...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[3.373710...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>14a2516a-b190-4cc5-8a24-cdff08e56aa8</td>\n",
       "      <td>S2A_MSIL1C_20250101T104441_N0511_R008_T32UMA_2...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>308916404</td>\n",
       "      <td>2025-01-01T16:35:03.000000Z</td>\n",
       "      <td>2025-01-01T16:45:00.905462Z</td>\n",
       "      <td>2025-01-01T16:51:37.444935Z</td>\n",
       "      <td>True</td>\n",
       "      <td>9999-12-31T23:59:59.999999Z</td>\n",
       "      <td>/eodata/Sentinel-2/MSI/L1C/2025/01/01/S2A_MSIL...</td>\n",
       "      <td>[{'Value': '27e72a589cf5b7cfa1158e0103b41899',...</td>\n",
       "      <td>{'Start': '2025-01-01T10:44:41.024000Z', 'End'...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((8.44047647807030...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[8.440476...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>167bd96e-d461-4e7b-8526-4243907a9deb</td>\n",
       "      <td>S2A_MSIL1C_20250101T104441_N0511_R008_T32ULA_2...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>667512989</td>\n",
       "      <td>2025-01-01T16:34:58.000000Z</td>\n",
       "      <td>2025-01-01T16:42:30.861623Z</td>\n",
       "      <td>2025-01-01T16:54:41.662375Z</td>\n",
       "      <td>True</td>\n",
       "      <td>9999-12-31T23:59:59.999999Z</td>\n",
       "      <td>/eodata/Sentinel-2/MSI/L1C/2025/01/01/S2A_MSIL...</td>\n",
       "      <td>[{'Value': '84fa43cda3d1f873716f9760b9f957a6',...</td>\n",
       "      <td>{'Start': '2025-01-01T10:44:41.024000Z', 'End'...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((6.17866751641768...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[6.178667...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>244a1c18-bc7f-490b-9b58-eb8fbee3fcbf</td>\n",
       "      <td>S2A_MSIL2A_20250101T104441_N0511_R008_T32UMA_2...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>375105849</td>\n",
       "      <td>2025-01-01T17:36:47.000000Z</td>\n",
       "      <td>2025-01-01T17:47:28.433813Z</td>\n",
       "      <td>2025-01-01T17:59:45.560303Z</td>\n",
       "      <td>True</td>\n",
       "      <td>9999-12-31T23:59:59.999999Z</td>\n",
       "      <td>/eodata/Sentinel-2/MSI/L2A/2025/01/01/S2A_MSIL...</td>\n",
       "      <td>[{'Value': 'd25738a6851fbca38e43f074928aad4d',...</td>\n",
       "      <td>{'Start': '2025-01-01T10:44:41.024000Z', 'End'...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((8.44047647807030...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[8.440476...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>f590bcc2-35bb-4a8d-86d5-f659a2acbaeb</td>\n",
       "      <td>S2A_MSIL2A_20250115T102351_N0511_R065_T32TPR_2...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>858911530</td>\n",
       "      <td>2025-01-15T15:27:33.000000Z</td>\n",
       "      <td>2025-01-15T15:32:54.876941Z</td>\n",
       "      <td>2025-01-15T15:34:01.765365Z</td>\n",
       "      <td>True</td>\n",
       "      <td>9999-12-31T23:59:59.999999Z</td>\n",
       "      <td>/eodata/Sentinel-2/MSI/L2A/2025/01/15/S2A_MSIL...</td>\n",
       "      <td>[{'Value': 'd3e177e5139a152581a0fdac12eb062b',...</td>\n",
       "      <td>{'Start': '2025-01-15T10:23:51.024000Z', 'End'...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((11.4066800060693...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[11.40668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>f62f96d3-613b-4db8-a26e-9adc9e297b91</td>\n",
       "      <td>S2A_MSIL1C_20250115T102351_N0511_R065_T32TPT_2...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>723303564</td>\n",
       "      <td>2025-01-15T14:25:50.000000Z</td>\n",
       "      <td>2025-01-15T14:33:18.555948Z</td>\n",
       "      <td>2025-01-15T14:49:28.257447Z</td>\n",
       "      <td>True</td>\n",
       "      <td>9999-12-31T23:59:59.999999Z</td>\n",
       "      <td>/eodata/Sentinel-2/MSI/L1C/2025/01/15/S2A_MSIL...</td>\n",
       "      <td>[{'Value': '80aa7623f714f89f92457890da3de432',...</td>\n",
       "      <td>{'Start': '2025-01-15T10:23:51.024000Z', 'End'...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((11.7513641173473...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[11.75136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>f89324d1-be62-4672-9368-7de499a01745</td>\n",
       "      <td>S2A_MSIL2A_20250115T102351_N0511_R065_T32UMA_2...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>112446571</td>\n",
       "      <td>2025-01-15T13:02:23.030747Z</td>\n",
       "      <td>2025-01-15T13:02:23.030747Z</td>\n",
       "      <td>2025-01-15T13:18:48.811076Z</td>\n",
       "      <td>True</td>\n",
       "      <td>9999-12-31T23:59:59.999999Z</td>\n",
       "      <td>/eodata/Sentinel-2/MSI/L2A/2025/01/15/S2A_MSIL...</td>\n",
       "      <td>[{'Value': '9f6d95ee4aa3eb0e9c4b584497a53a7d',...</td>\n",
       "      <td>{'Start': '2025-01-15T10:23:51.024000Z', 'End'...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((8.76275777631883...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[8.762757...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>f984b37f-c79a-4aa8-b008-8b862cb60ff9</td>\n",
       "      <td>S2A_MSIL1C_20250115T102351_N0511_R065_T32TMR_2...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>840797059</td>\n",
       "      <td>2025-01-15T14:26:04.000000Z</td>\n",
       "      <td>2025-01-15T14:32:44.978969Z</td>\n",
       "      <td>2025-01-15T14:34:19.232370Z</td>\n",
       "      <td>True</td>\n",
       "      <td>9999-12-31T23:59:59.999999Z</td>\n",
       "      <td>/eodata/Sentinel-2/MSI/L1C/2025/01/15/S2A_MSIL...</td>\n",
       "      <td>[{'Value': '005f85e39d4004cd3cb331bcb2da6cac',...</td>\n",
       "      <td>{'Start': '2025-01-15T10:23:51.024000Z', 'End'...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((7.70695108472353...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[7.706951...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>fb3e2482-649f-435a-a667-159e193d6900</td>\n",
       "      <td>S2A_MSIL1C_20250115T102351_N0511_R065_T32TLR_2...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>378384729</td>\n",
       "      <td>2025-01-15T14:25:40.000000Z</td>\n",
       "      <td>2025-01-15T14:30:47.899558Z</td>\n",
       "      <td>2025-01-15T14:32:00.153069Z</td>\n",
       "      <td>True</td>\n",
       "      <td>9999-12-31T23:59:59.999999Z</td>\n",
       "      <td>/eodata/Sentinel-2/MSI/L1C/2025/01/15/S2A_MSIL...</td>\n",
       "      <td>[{'Value': 'd01ca9672126b6803464de0f1b0f69bc',...</td>\n",
       "      <td>{'Start': '2025-01-15T10:23:51.024000Z', 'End'...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((7.13042766494800...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[7.130427...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      @odata.mediaContentType                                    Id  \\\n",
       "0    application/octet-stream  02382b16-7ac4-44c7-b095-1fcd2c7e0770   \n",
       "1    application/octet-stream  046245ff-ff34-4cec-879a-d768ad514dbc   \n",
       "2    application/octet-stream  14a2516a-b190-4cc5-8a24-cdff08e56aa8   \n",
       "3    application/octet-stream  167bd96e-d461-4e7b-8526-4243907a9deb   \n",
       "4    application/octet-stream  244a1c18-bc7f-490b-9b58-eb8fbee3fcbf   \n",
       "..                        ...                                   ...   \n",
       "567  application/octet-stream  f590bcc2-35bb-4a8d-86d5-f659a2acbaeb   \n",
       "568  application/octet-stream  f62f96d3-613b-4db8-a26e-9adc9e297b91   \n",
       "569  application/octet-stream  f89324d1-be62-4672-9368-7de499a01745   \n",
       "570  application/octet-stream  f984b37f-c79a-4aa8-b008-8b862cb60ff9   \n",
       "571  application/octet-stream  fb3e2482-649f-435a-a667-159e193d6900   \n",
       "\n",
       "                                                  Name  \\\n",
       "0    S2A_MSIL2A_20250101T104441_N0511_R008_T31TGM_2...   \n",
       "1    S2A_MSIL2A_20250101T104441_N0511_R008_T31UEQ_2...   \n",
       "2    S2A_MSIL1C_20250101T104441_N0511_R008_T32UMA_2...   \n",
       "3    S2A_MSIL1C_20250101T104441_N0511_R008_T32ULA_2...   \n",
       "4    S2A_MSIL2A_20250101T104441_N0511_R008_T32UMA_2...   \n",
       "..                                                 ...   \n",
       "567  S2A_MSIL2A_20250115T102351_N0511_R065_T32TPR_2...   \n",
       "568  S2A_MSIL1C_20250115T102351_N0511_R065_T32TPT_2...   \n",
       "569  S2A_MSIL2A_20250115T102351_N0511_R065_T32UMA_2...   \n",
       "570  S2A_MSIL1C_20250115T102351_N0511_R065_T32TMR_2...   \n",
       "571  S2A_MSIL1C_20250115T102351_N0511_R065_T32TLR_2...   \n",
       "\n",
       "                  ContentType  ContentLength                   OriginDate  \\\n",
       "0    application/octet-stream      961041063  2025-01-01T17:37:03.000000Z   \n",
       "1    application/octet-stream      563963564  2025-01-01T17:36:16.000000Z   \n",
       "2    application/octet-stream      308916404  2025-01-01T16:35:03.000000Z   \n",
       "3    application/octet-stream      667512989  2025-01-01T16:34:58.000000Z   \n",
       "4    application/octet-stream      375105849  2025-01-01T17:36:47.000000Z   \n",
       "..                        ...            ...                          ...   \n",
       "567  application/octet-stream      858911530  2025-01-15T15:27:33.000000Z   \n",
       "568  application/octet-stream      723303564  2025-01-15T14:25:50.000000Z   \n",
       "569  application/octet-stream      112446571  2025-01-15T13:02:23.030747Z   \n",
       "570  application/octet-stream      840797059  2025-01-15T14:26:04.000000Z   \n",
       "571  application/octet-stream      378384729  2025-01-15T14:25:40.000000Z   \n",
       "\n",
       "                 PublicationDate             ModificationDate  Online  \\\n",
       "0    2025-01-01T17:47:35.830573Z  2025-01-01T17:58:34.626246Z    True   \n",
       "1    2025-01-01T17:48:15.562066Z  2025-01-01T17:48:43.236298Z    True   \n",
       "2    2025-01-01T16:45:00.905462Z  2025-01-01T16:51:37.444935Z    True   \n",
       "3    2025-01-01T16:42:30.861623Z  2025-01-01T16:54:41.662375Z    True   \n",
       "4    2025-01-01T17:47:28.433813Z  2025-01-01T17:59:45.560303Z    True   \n",
       "..                           ...                          ...     ...   \n",
       "567  2025-01-15T15:32:54.876941Z  2025-01-15T15:34:01.765365Z    True   \n",
       "568  2025-01-15T14:33:18.555948Z  2025-01-15T14:49:28.257447Z    True   \n",
       "569  2025-01-15T13:02:23.030747Z  2025-01-15T13:18:48.811076Z    True   \n",
       "570  2025-01-15T14:32:44.978969Z  2025-01-15T14:34:19.232370Z    True   \n",
       "571  2025-01-15T14:30:47.899558Z  2025-01-15T14:32:00.153069Z    True   \n",
       "\n",
       "                    EvictionDate  \\\n",
       "0    9999-12-31T23:59:59.999999Z   \n",
       "1    9999-12-31T23:59:59.999999Z   \n",
       "2    9999-12-31T23:59:59.999999Z   \n",
       "3    9999-12-31T23:59:59.999999Z   \n",
       "4    9999-12-31T23:59:59.999999Z   \n",
       "..                           ...   \n",
       "567  9999-12-31T23:59:59.999999Z   \n",
       "568  9999-12-31T23:59:59.999999Z   \n",
       "569  9999-12-31T23:59:59.999999Z   \n",
       "570  9999-12-31T23:59:59.999999Z   \n",
       "571  9999-12-31T23:59:59.999999Z   \n",
       "\n",
       "                                                S3Path  \\\n",
       "0    /eodata/Sentinel-2/MSI/L2A/2025/01/01/S2A_MSIL...   \n",
       "1    /eodata/Sentinel-2/MSI/L2A/2025/01/01/S2A_MSIL...   \n",
       "2    /eodata/Sentinel-2/MSI/L1C/2025/01/01/S2A_MSIL...   \n",
       "3    /eodata/Sentinel-2/MSI/L1C/2025/01/01/S2A_MSIL...   \n",
       "4    /eodata/Sentinel-2/MSI/L2A/2025/01/01/S2A_MSIL...   \n",
       "..                                                 ...   \n",
       "567  /eodata/Sentinel-2/MSI/L2A/2025/01/15/S2A_MSIL...   \n",
       "568  /eodata/Sentinel-2/MSI/L1C/2025/01/15/S2A_MSIL...   \n",
       "569  /eodata/Sentinel-2/MSI/L2A/2025/01/15/S2A_MSIL...   \n",
       "570  /eodata/Sentinel-2/MSI/L1C/2025/01/15/S2A_MSIL...   \n",
       "571  /eodata/Sentinel-2/MSI/L1C/2025/01/15/S2A_MSIL...   \n",
       "\n",
       "                                              Checksum  \\\n",
       "0    [{'Value': '4230923f6a24befaccaddde4dddf73c2',...   \n",
       "1    [{'Value': 'f8e719d4ff70edd1384f7619458a4ea5',...   \n",
       "2    [{'Value': '27e72a589cf5b7cfa1158e0103b41899',...   \n",
       "3    [{'Value': '84fa43cda3d1f873716f9760b9f957a6',...   \n",
       "4    [{'Value': 'd25738a6851fbca38e43f074928aad4d',...   \n",
       "..                                                 ...   \n",
       "567  [{'Value': 'd3e177e5139a152581a0fdac12eb062b',...   \n",
       "568  [{'Value': '80aa7623f714f89f92457890da3de432',...   \n",
       "569  [{'Value': '9f6d95ee4aa3eb0e9c4b584497a53a7d',...   \n",
       "570  [{'Value': '005f85e39d4004cd3cb331bcb2da6cac',...   \n",
       "571  [{'Value': 'd01ca9672126b6803464de0f1b0f69bc',...   \n",
       "\n",
       "                                           ContentDate  \\\n",
       "0    {'Start': '2025-01-01T10:44:41.024000Z', 'End'...   \n",
       "1    {'Start': '2025-01-01T10:44:41.024000Z', 'End'...   \n",
       "2    {'Start': '2025-01-01T10:44:41.024000Z', 'End'...   \n",
       "3    {'Start': '2025-01-01T10:44:41.024000Z', 'End'...   \n",
       "4    {'Start': '2025-01-01T10:44:41.024000Z', 'End'...   \n",
       "..                                                 ...   \n",
       "567  {'Start': '2025-01-15T10:23:51.024000Z', 'End'...   \n",
       "568  {'Start': '2025-01-15T10:23:51.024000Z', 'End'...   \n",
       "569  {'Start': '2025-01-15T10:23:51.024000Z', 'End'...   \n",
       "570  {'Start': '2025-01-15T10:23:51.024000Z', 'End'...   \n",
       "571  {'Start': '2025-01-15T10:23:51.024000Z', 'End'...   \n",
       "\n",
       "                                             Footprint  \\\n",
       "0    geography'SRID=4326;POLYGON ((6.73372898013687...   \n",
       "1    geography'SRID=4326;POLYGON ((3.37371033145457...   \n",
       "2    geography'SRID=4326;POLYGON ((8.44047647807030...   \n",
       "3    geography'SRID=4326;POLYGON ((6.17866751641768...   \n",
       "4    geography'SRID=4326;POLYGON ((8.44047647807030...   \n",
       "..                                                 ...   \n",
       "567  geography'SRID=4326;POLYGON ((11.4066800060693...   \n",
       "568  geography'SRID=4326;POLYGON ((11.7513641173473...   \n",
       "569  geography'SRID=4326;POLYGON ((8.76275777631883...   \n",
       "570  geography'SRID=4326;POLYGON ((7.70695108472353...   \n",
       "571  geography'SRID=4326;POLYGON ((7.13042766494800...   \n",
       "\n",
       "                                          GeoFootprint  \n",
       "0    {'type': 'Polygon', 'coordinates': [[[6.733728...  \n",
       "1    {'type': 'Polygon', 'coordinates': [[[3.373710...  \n",
       "2    {'type': 'Polygon', 'coordinates': [[[8.440476...  \n",
       "3    {'type': 'Polygon', 'coordinates': [[[6.178667...  \n",
       "4    {'type': 'Polygon', 'coordinates': [[[8.440476...  \n",
       "..                                                 ...  \n",
       "567  {'type': 'Polygon', 'coordinates': [[[11.40668...  \n",
       "568  {'type': 'Polygon', 'coordinates': [[[11.75136...  \n",
       "569  {'type': 'Polygon', 'coordinates': [[[8.762757...  \n",
       "570  {'type': 'Polygon', 'coordinates': [[[7.706951...  \n",
       "571  {'type': 'Polygon', 'coordinates': [[[7.130427...  \n",
       "\n",
       "[572 rows x 15 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3e755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_processor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
