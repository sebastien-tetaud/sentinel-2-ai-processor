{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54204005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import loguru\n",
    "from data.dataset import Sentinel2Dataset\n",
    "from data.loader import define_loaders\n",
    "from utils.utils import load_config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model_zoo.models import define_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2749814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(config_path=\"cfg/config.yaml\")\n",
    "BASE_DIR = config[\"DATASET\"][\"base_dir\"]\n",
    "VERSION = config['DATASET']['version']\n",
    "BATCH_SIZE = config['TRAINING']['batch_size']\n",
    "NUM_WORKERS = config['TRAINING']['num_workers']\n",
    "RESIZE = config['TRAINING']['resize']\n",
    "LEARNING_RATE = config['TRAINING']['learning_rate']\n",
    "train_path = f\"{BASE_DIR}/{VERSION}/train_path.csv\"\n",
    "val_path = f\"{BASE_DIR}/{VERSION}/val_path.csv\"\n",
    "test_path = f\"{BASE_DIR}/{VERSION}/test_path.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7729529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_path)\n",
    "df_val = pd.read_csv(val_path)\n",
    "df_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a3de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Sentinel2Dataset(df_path=df_train,\n",
    "                                 train=True, augmentation=False,\n",
    "                                 img_size=RESIZE)\n",
    "\n",
    "val_dataset = Sentinel2Dataset(df_path=df_val,\n",
    "                               train=False, augmentation=False,\n",
    "                               img_size=RESIZE)\n",
    "\n",
    "test_dataset = Sentinel2Dataset(df_path=df_test,\n",
    "                                 train=True, augmentation=False,\n",
    "                                 img_size=RESIZE)\n",
    "\n",
    "train_loader, val_loader = define_loaders(\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        train=True,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "test_loader =  define_loaders(\n",
    "        train_dataset=test_dataset,\n",
    "        val_dataset=None,\n",
    "        train=False,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7df3ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.torch import load_model_weights\n",
    "\n",
    "\n",
    "model = define_model(name=\"Unet\", encoder_name=\"resnet34\",\n",
    "                     in_channel=3, out_channels=3, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1899cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from /home/ubuntu/project/sentinel-2-ai-processor/results/checkpoints/best_model.pth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights_path =\"/home/ubuntu/project/sentinel-2-ai-processor/results/checkpoints/best_model.pth\"\n",
    "model = load_model_weights(model=model, filename=weights_path)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5beb2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'mse': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b1308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0  # Changed variable name from val_loss to test_loss\n",
    "criterion = nn.MSELoss()\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(test_dataset), colour='#f4d160') as t:\n",
    "        t.set_description('testing')  # Changed from 'validation' to 'testing'\n",
    "\n",
    "        for batch_idx, (x_data, y_data) in enumerate(test_loader):\n",
    "            x_data = x_data.to(device)\n",
    "            y_data = y_data.to(device)\n",
    "            valid_mask = (y_data >= 0)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(x_data)\n",
    "            loss = criterion(outputs[valid_mask], y_data[valid_mask])\n",
    "\n",
    "            # Update statistics\n",
    "            batch_loss = loss.item()\n",
    "            test_loss += batch_loss\n",
    "\n",
    "            # Update progress bar\n",
    "            t.set_postfix(loss=batch_loss)\n",
    "            t.update(x_data.size(0))\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "metrics_dict['test_loss'] = avg_test_loss  # You might need to update this line\n",
    "# or metrics_dict['mse'].append(avg_test_loss)\n",
    "print(f'Test Loss: {avg_test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76f914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation phase\n",
    "\n",
    "metrics_dict = {\n",
    "    'val_loss': [],\n",
    "    'val_psrn':[]\n",
    "\n",
    "}\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "criterion = nn.MSELoss()\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(val_dataset), ncols=100, colour='#f4d160') as t:\n",
    "        t.set_description('validation')\n",
    "\n",
    "        for batch_idx, (x_data, y_data) in enumerate(val_loader):\n",
    "            x_data = x_data.to(device)\n",
    "            y_data = y_data.to(device)\n",
    "            valid_mask = (y_data >= 0)\n",
    "\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(x_data)\n",
    "            loss = criterion(outputs[valid_mask], y_data[valid_mask] )\n",
    "\n",
    "\n",
    "            # Update statistics\n",
    "            batch_loss = loss.item()\n",
    "            val_loss += batch_loss\n",
    "\n",
    "            metric = PeakSignalNoiseRatio()\n",
    "            metric.update(outputs[valid_mask], y_data[valid_mask])\n",
    "            metrics_dict['val_psrn'].append(float(metric.compute().cpu().numpy()))\n",
    "\n",
    "\n",
    "            # Update progress bar\n",
    "            t.set_postfix(loss=batch_loss)\n",
    "            t.update(x_data.size(0))\n",
    "\n",
    "avg_val_loss = val_loss / len(val_loader)\n",
    "metrics_dict['val_loss'].append(avg_val_loss)\n",
    "metrics_dict['val_psrn'] = np.sum(metrics_dict['val_psrn'])/len(metrics_dict['val_psrn'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193778ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b5857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torcheval.metrics.image.psnr.PeakSignalNoiseRatio"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test PSNR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'val_loss': [],\n",
    "    'val_psrn':[],\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90f97bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_mse': [], 'test_psnr': {'02': [], '03': [], '04': []}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "bands = [\"02\", \"03\", \"04\"]\n",
    "\n",
    "test_metrics = {\n",
    "    \"test_mse\": [],\n",
    "    \"test_psnr\": {band: [] for band in bands}\n",
    "}\n",
    "\n",
    "\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b5fa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: : 192it [00:06, 30.00it/s, loss=0.00764]                                                   ?, ?it/s, loss=0.0174]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test loss: 0.007191286305896938\n",
      "Band 02: PSNR (torcheval): 21.4727\n",
      "Band 03: PSNR (torcheval): 21.4488\n",
      "Band 04: PSNR (torcheval): 21.3749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bands = [\"02\", \"03\", \"04\"]\n",
    "\n",
    "test_metrics = {\n",
    "    \"test_mse\": [],\n",
    "    \"test_psnr\": {band: [] for band in bands}\n",
    "}\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# We first assume that the output has the shape (N, C, H, W).\n",
    "# For example, if you expect 3 channels:\n",
    "num_channels = len(bands)  # Use the number of bands as num_channels\n",
    "\n",
    "# Create one metric instance per channel for both libraries and move them to the correct device.\n",
    "psnr_channels = [\n",
    "    PeakSignalNoiseRatio(data_range=1.0).to(device) for _ in range(num_channels)\n",
    "]\n",
    "\n",
    "total_test_loss = 0.0  # Changed variable name from total_val_loss to total_test_loss\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(test_loader), ncols=100, colour='#f4d160') as t:\n",
    "        t.set_description('testing')  # Changed description from 'validation' to 'testing'\n",
    "        for batch_idx, (x_data, y_data) in enumerate(test_loader):\n",
    "            # Move inputs and targets to the device\n",
    "            x_data = x_data.to(device)\n",
    "            y_data = y_data.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(x_data)  # Expected shape: (N, C, H, W)\n",
    "\n",
    "            # Apply a valid mask if needed. Here we assume that each pixel in each channel\n",
    "            # that is < 0 in the ground truth should be ignored.\n",
    "            # We'll update the metrics for each channel independently.\n",
    "            for c, band in enumerate(bands):\n",
    "                # Extract channel c for both outputs and targets.\n",
    "                outputs_c = outputs[:, c, :, :]\n",
    "                y_c = y_data[:, c, :, :]\n",
    "\n",
    "                # Create channel-wise valid mask. This mask is True for valid pixels.\n",
    "                valid_mask_c = (y_c >= 0)\n",
    "\n",
    "                # Select only the valid pixels.\n",
    "                outputs_valid_c = outputs_c[valid_mask_c]\n",
    "                y_valid_c = y_c[valid_mask_c]\n",
    "\n",
    "                # Update the metrics for this channel.\n",
    "                psnr_channels[c].update(outputs_valid_c, y_valid_c)\n",
    "\n",
    "                # Update test_psnr for this band\n",
    "                test_metrics[\"test_psnr\"][band].append(psnr_channels[c].compute().item())\n",
    "\n",
    "            # (Optional) Compute loss for your purposes. Here, for simplicity, we compute the loss\n",
    "            # on all channels combined using the valid mask across the whole target.\n",
    "            # Adjust this if you want a channel-wise loss.\n",
    "            # Here, we create a combined valid mask over all channels.\n",
    "            valid_mask_all = (y_data >= 0)\n",
    "            loss = criterion(outputs[valid_mask_all], y_data[valid_mask_all])\n",
    "            batch_loss = loss.item()\n",
    "            total_test_loss += batch_loss\n",
    "            t.set_postfix(loss=batch_loss)\n",
    "            t.update(x_data.size(0))\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)  # Changed variable name from len(val_loader) to len(test_loader)\n",
    "test_metrics[\"test_mse\"].append(avg_test_loss)\n",
    "print(f\"Average test loss: {avg_test_loss}\")\n",
    "\n",
    "# You can now access the PSNR values for each band\n",
    "for band in bands:\n",
    "    print(f\"Band {band}: PSNR (torcheval): {test_metrics['test_psnr'][band][-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90da21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr_channels = [\n",
    "    PeakSignalNoiseRatio(data_range=1.0).to(device) for _ in range(num_channels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb89987e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PeakSignalNoiseRatio(), PeakSignalNoiseRatio(), PeakSignalNoiseRatio()]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psnr_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4fbcdd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'is_floating_point'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpsnr_channels\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai_processor/lib/python3.12/site-packages/torchmetrics/metric.py:549\u001b[39m, in \u001b[36mMetric._wrap_update.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m._enable_grad):\n\u001b[32m    548\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    551\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected all tensors to be on\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai_processor/lib/python3.12/site-packages/torchmetrics/image/psnr.py:133\u001b[39m, in \u001b[36mPeakSignalNoiseRatio.update\u001b[39m\u001b[34m(self, preds, target)\u001b[39m\n\u001b[32m    130\u001b[39m     preds = \u001b[38;5;28mself\u001b[39m.clamping_fn(preds)\n\u001b[32m    131\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.clamping_fn(target)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m sum_squared_error, num_obs = \u001b[43m_psnr_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data_range \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    136\u001b[39m         \u001b[38;5;66;03m# keep track of min and max target values\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai_processor/lib/python3.12/site-packages/torchmetrics/functional/image/psnr.py:72\u001b[39m, in \u001b[36m_psnr_update\u001b[39m\u001b[34m(preds, target, dim)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_psnr_update\u001b[39m(\n\u001b[32m     59\u001b[39m     preds: Tensor,\n\u001b[32m     60\u001b[39m     target: Tensor,\n\u001b[32m     61\u001b[39m     dim: Optional[Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, ...]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     62\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[Tensor, Tensor]:\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Update and return variables required to compute peak signal-to-noise ratio.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mpreds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m():\n\u001b[32m     73\u001b[39m         preds = preds.to(torch.float32)\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m target.is_floating_point():\n",
      "\u001b[31mAttributeError\u001b[39m: 'float' object has no attribute 'is_floating_point'"
     ]
    }
   ],
   "source": [
    "psnr_channels[0].update(0.5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff5bc34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_processor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
