{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54204005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import loguru\n",
    "from data.dataset import Sentinel2Dataset\n",
    "from data.loader import define_loaders\n",
    "from utils.utils import load_config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model_zoo.models import define_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2749814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(config_path=\"cfg/config.yaml\")\n",
    "BASE_DIR = config[\"DATASET\"][\"base_dir\"]\n",
    "VERSION = config['DATASET']['version']\n",
    "BATCH_SIZE = config['TRAINING']['batch_size']\n",
    "NUM_WORKERS = config['TRAINING']['num_workers']\n",
    "RESIZE = config['TRAINING']['resize']\n",
    "LEARNING_RATE = config['TRAINING']['learning_rate']\n",
    "train_path = f\"{BASE_DIR}/{VERSION}/train_path.csv\"\n",
    "val_path = f\"{BASE_DIR}/{VERSION}/val_path.csv\"\n",
    "test_path = f\"{BASE_DIR}/{VERSION}/test_path.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7729529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_path)\n",
    "df_val = pd.read_csv(val_path)\n",
    "df_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43a3de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Sentinel2Dataset(df_path=df_train,\n",
    "                                 train=True, augmentation=False,\n",
    "                                 img_size=RESIZE)\n",
    "\n",
    "val_dataset = Sentinel2Dataset(df_path=df_val,\n",
    "                               train=False, augmentation=False,\n",
    "                               img_size=RESIZE)\n",
    "\n",
    "test_dataset = Sentinel2Dataset(df_path=df_test,\n",
    "                                 train=True, augmentation=False,\n",
    "                                 img_size=RESIZE)\n",
    "\n",
    "train_loader, val_loader = define_loaders(\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        train=True,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "test_loader =  define_loaders(\n",
    "        train_dataset=test_dataset,\n",
    "        val_dataset=None,\n",
    "        train=False,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7df3ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.torch import load_model_weights\n",
    "\n",
    "\n",
    "model = define_model(name=\"Unet\", encoder_name=\"resnet34\",\n",
    "                     in_channel=3, out_channels=3, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1899cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from /home/ubuntu/project/sentinel-2-ai-processor/src/checkpoints/best_model.pth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights_path =\"/home/ubuntu/project/sentinel-2-ai-processor/src/checkpoints/best_model.pth\"\n",
    "\n",
    "model = load_model_weights(model=model, filename=weights_path)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7095c607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5beb2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'mse': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b1308d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing:  96%|\u001b[38;2;244;209;96m█████████▌\u001b[0m| 192/200 [00:07<00:00, 24.02it/s, loss=0.0128] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.007088003951745729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0  # Changed variable name from val_loss to test_loss\n",
    "criterion = nn.MSELoss()\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(test_dataset), colour='#f4d160') as t:\n",
    "        t.set_description('testing')  # Changed from 'validation' to 'testing'\n",
    "\n",
    "        for batch_idx, (x_data, y_data) in enumerate(test_loader):\n",
    "            x_data = x_data.to(device)\n",
    "            y_data = y_data.to(device)\n",
    "            valid_mask = (y_data >= 0)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(x_data)\n",
    "            loss = criterion(outputs[valid_mask], y_data[valid_mask])\n",
    "\n",
    "            # Update statistics\n",
    "            batch_loss = loss.item()\n",
    "            test_loss += batch_loss\n",
    "\n",
    "            # Update progress bar\n",
    "            t.set_postfix(loss=batch_loss)\n",
    "            t.update(x_data.size(0))\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "metrics_dict['test_loss'] = avg_test_loss  # You might need to update this line\n",
    "# or metrics_dict['mse'].append(avg_test_loss)\n",
    "print(f'Test Loss: {avg_test_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76f914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save metrics\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Plot loss curves\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(metrics_dict['train_loss'], label='Train Loss')\n",
    "# plt.plot(metrics_dict['val_loss'], label='Validation Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss (MSE)')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.legend()\n",
    "# plt.savefig(f\"{save_path}/loss_curves.png\")\n",
    "# logger.info(f\"Loss curves saved to {save_path}/loss_curves.png\")\n",
    "\n",
    "# # Optionally, test the model on a few validation samples\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for i, (x_data, y_data) in enumerate(val_loader):\n",
    "#         if i >= 12:\n",
    "#             break\n",
    "\n",
    "#         x_data = x_data.to(device)\n",
    "#         y_data = y_data.to(device)\n",
    "\n",
    "#         output = model(x_data)\n",
    "\n",
    "#         # Convert to numpy for visualization\n",
    "#         x_np = x_data.cpu().numpy()[0].transpose(1, 2, 0)  # First image in batch, CHW to HWC\n",
    "#         y_np = y_data.cpu().numpy()[0].transpose(1, 2, 0)\n",
    "#         pred_np = output.cpu().numpy()[0].transpose(1, 2, 0)\n",
    "#         # Clip values to valid range for visualization\n",
    "#         x_np = np.clip(x_np, 0, 1)\n",
    "#         y_np = np.clip(y_np, 0, 1)\n",
    "#         pred_np = np.clip(pred_np, 0, 1)\n",
    "\n",
    "#         # Plot and save\n",
    "#         fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "#         axs[0].imshow(x_np)\n",
    "#         axs[0].set_title('L1C Input')\n",
    "#         axs[1].imshow(pred_np)\n",
    "#         axs[1].set_title('Model Output')\n",
    "#         axs[2].imshow(y_np)\n",
    "#         axs[2].set_title('L2A Ground Truth')\n",
    "\n",
    "#         plt.savefig(f\"{save_path}/sample_{i}_prediction.png\")\n",
    "#         plt.close()\n",
    "\n",
    "# logger.info(\"Testing completed. Sample predictions saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_processor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
