{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54204005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/ai_processor/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import loguru\n",
    "from data.dataset import Sentinel2Dataset\n",
    "from data.loader import define_loaders\n",
    "from utils.utils import load_config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model_zoo.models import define_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2749814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(config_path=\"cfg/config.yaml\")\n",
    "BASE_DIR = config[\"DATASET\"][\"base_dir\"]\n",
    "VERSION = config['DATASET']['version']\n",
    "BATCH_SIZE = config['TRAINING']['batch_size']\n",
    "NUM_WORKERS = config['TRAINING']['num_workers']\n",
    "RESIZE = config['TRAINING']['resize']\n",
    "LEARNING_RATE = config['TRAINING']['learning_rate']\n",
    "train_path = f\"{BASE_DIR}/{VERSION}/train_path.csv\"\n",
    "val_path = f\"{BASE_DIR}/{VERSION}/val_path.csv\"\n",
    "test_path = f\"{BASE_DIR}/{VERSION}/test_path.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7729529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_path)\n",
    "df_val = pd.read_csv(val_path)\n",
    "df_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a3de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Sentinel2Dataset(df_path=df_train,\n",
    "                                 train=True, augmentation=False,\n",
    "                                 img_size=RESIZE)\n",
    "\n",
    "val_dataset = Sentinel2Dataset(df_path=df_val,\n",
    "                               train=False, augmentation=False,\n",
    "                               img_size=RESIZE)\n",
    "\n",
    "test_dataset = Sentinel2Dataset(df_path=df_test,\n",
    "                                 train=True, augmentation=False,\n",
    "                                 img_size=RESIZE)\n",
    "\n",
    "train_loader, val_loader = define_loaders(\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        train=True,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "test_loader =  define_loaders(\n",
    "        train_dataset=test_dataset,\n",
    "        val_dataset=None,\n",
    "        train=False,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7df3ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.torch import load_model_weights\n",
    "\n",
    "\n",
    "model = define_model(name=\"Unet\", encoder_name=\"resnet34\",\n",
    "                     in_channel=3, out_channels=3, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1899cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from /home/ubuntu/project/sentinel-2-ai-processor/results/checkpoints/best_model.pth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights_path =\"/home/ubuntu/project/sentinel-2-ai-processor/results/checkpoints/best_model.pth\"\n",
    "model = load_model_weights(model=model, filename=weights_path)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5beb2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'mse': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b1308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0  # Changed variable name from val_loss to test_loss\n",
    "criterion = nn.MSELoss()\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(test_dataset), colour='#f4d160') as t:\n",
    "        t.set_description('testing')  # Changed from 'validation' to 'testing'\n",
    "\n",
    "        for batch_idx, (x_data, y_data) in enumerate(test_loader):\n",
    "            x_data = x_data.to(device)\n",
    "            y_data = y_data.to(device)\n",
    "            valid_mask = (y_data >= 0)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(x_data)\n",
    "            loss = criterion(outputs[valid_mask], y_data[valid_mask])\n",
    "\n",
    "            # Update statistics\n",
    "            batch_loss = loss.item()\n",
    "            test_loss += batch_loss\n",
    "\n",
    "            # Update progress bar\n",
    "            t.set_postfix(loss=batch_loss)\n",
    "            t.update(x_data.size(0))\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "metrics_dict['test_loss'] = avg_test_loss  # You might need to update this line\n",
    "# or metrics_dict['mse'].append(avg_test_loss)\n",
    "print(f'Test Loss: {avg_test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76f914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation phase\n",
    "\n",
    "metrics_dict = {\n",
    "    'val_loss': [],\n",
    "    'val_psrn':[]\n",
    "\n",
    "}\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "criterion = nn.MSELoss()\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(val_dataset), ncols=100, colour='#f4d160') as t:\n",
    "        t.set_description('validation')\n",
    "\n",
    "        for batch_idx, (x_data, y_data) in enumerate(val_loader):\n",
    "            x_data = x_data.to(device)\n",
    "            y_data = y_data.to(device)\n",
    "            valid_mask = (y_data >= 0)\n",
    "\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(x_data)\n",
    "            loss = criterion(outputs[valid_mask], y_data[valid_mask] )\n",
    "\n",
    "\n",
    "            # Update statistics\n",
    "            batch_loss = loss.item()\n",
    "            val_loss += batch_loss\n",
    "\n",
    "            metric = PeakSignalNoiseRatio()\n",
    "            metric.update(outputs[valid_mask], y_data[valid_mask])\n",
    "            metrics_dict['val_psrn'].append(float(metric.compute().cpu().numpy()))\n",
    "\n",
    "\n",
    "            # Update progress bar\n",
    "            t.set_postfix(loss=batch_loss)\n",
    "            t.update(x_data.size(0))\n",
    "\n",
    "avg_val_loss = val_loss / len(val_loader)\n",
    "metrics_dict['val_loss'].append(avg_val_loss)\n",
    "metrics_dict['val_psrn'] = np.sum(metrics_dict['val_psrn'])/len(metrics_dict['val_psrn'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193778ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b5857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torcheval.metrics.image.psnr.PeakSignalNoiseRatio"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test PSNR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'val_loss': [],\n",
    "    'val_psrn':[],\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f97bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: : 800it [00:20, 38.72it/s, loss=0.00171]                                                ?, ?it/s, loss=0.0128]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss: 0.0059565612766891715\n",
      "Channel 0: PSNR (torcheval): 22.2952, PSNR (torchmetrics): 22.2952\n",
      "Channel 1: PSNR (torcheval): 22.2825, PSNR (torchmetrics): 22.2825\n",
      "Channel 2: PSNR (torcheval): 22.1734, PSNR (torchmetrics): 22.1734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "\n",
    "# Assume these are already defined:\n",
    "# - model: Your model\n",
    "# - val_loader: DataLoader for your validation dataset\n",
    "# - device: torch.device(\"cuda\") or torch.device(\"cpu\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# We first assume that the output has the shape (N, C, H, W).\n",
    "# For example, if you expect 3 channels:\n",
    "num_channels = 3  # or set to the number of channels in your output\n",
    "\n",
    "# Create one metric instance per channel for both libraries and move them to the correct device.\n",
    "psnr_channels = [\n",
    "    PeakSignalNoiseRatio(data_range=1.0).to(device) for _ in range(num_channels)\n",
    "]\n",
    "\n",
    "\n",
    "total_val_loss = 0.0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(val_loader), ncols=100, colour='#f4d160') as t:\n",
    "        t.set_description('validation')\n",
    "        for batch_idx, (x_data, y_data) in enumerate(val_loader):\n",
    "            # Move inputs and targets to the device\n",
    "            x_data = x_data.to(device)\n",
    "            y_data = y_data.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(x_data)  # Expected shape: (N, C, H, W)\n",
    "\n",
    "            # Apply a valid mask if needed. Here we assume that each pixel in each channel\n",
    "            # that is < 0 in the ground truth should be ignored.\n",
    "            # We'll update the metrics for each channel independently.\n",
    "            for c in range(num_channels):\n",
    "                # Extract channel c for both outputs and targets.\n",
    "                outputs_c = outputs[:, c, :, :]\n",
    "                y_c = y_data[:, c, :, :]\n",
    "\n",
    "                # Create channel-wise valid mask. This mask is True for valid pixels.\n",
    "                valid_mask_c = (y_c >= 0)\n",
    "\n",
    "                # Select only the valid pixels.\n",
    "                outputs_valid_c = outputs_c[valid_mask_c]\n",
    "                y_valid_c = y_c[valid_mask_c]\n",
    "\n",
    "                # Update the metrics for this channel.\n",
    "                psnr_channels[c].update(outputs_valid_c, y_valid_c)\n",
    "\n",
    "            # (Optional) Compute loss for your purposes. Here, for simplicity, we compute the loss\n",
    "            # on all channels combined using the valid mask across the whole target.\n",
    "            # Adjust this if you want a channel-wise loss.\n",
    "            # Here, we create a combined valid mask over all channels.\n",
    "            valid_mask_all = (y_data >= 0)\n",
    "            loss = criterion(outputs[valid_mask_all], y_data[valid_mask_all])\n",
    "            batch_loss = loss.item()\n",
    "            total_val_loss += batch_loss\n",
    "\n",
    "            t.set_postfix(loss=batch_loss)\n",
    "            t.update(x_data.size(0))\n",
    "\n",
    "avg_val_loss = total_val_loss / len(val_loader)\n",
    "print(f\"Average validation loss: {avg_val_loss}\")\n",
    "\n",
    "# Compute and print final PSNR values for each channel.\n",
    "for c in range(num_channels):\n",
    "    final_psnr_torcheval = psnr_torcheval_channels[c].compute().item()\n",
    "    final_psnr_torchmetrics = psnr_torchmetrics_channels[c].compute().item()\n",
    "    print(f\"Channel {c}: PSNR (torcheval): {final_psnr_torcheval:.4f}, PSNR (torchmetrics): {final_psnr_torchmetrics:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15d84de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torcheval.metrics.image.psnr.PeakSignalNoiseRatio at 0x78a17c31e600>,\n",
       " <torcheval.metrics.image.psnr.PeakSignalNoiseRatio at 0x78a04b3d0620>,\n",
       " <torcheval.metrics.image.psnr.PeakSignalNoiseRatio at 0x78a16b835130>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psnr_torcheval_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143b3292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_processor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
